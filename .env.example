# S3-compatible endpoint (RustFS)
# Use 127.0.0.1 (not localhost) — Node 18 fetch resolves localhost to IPv6 ::1; Docker/Ollama may bind IPv4 only.
S3_ENDPOINT=http://127.0.0.1:9000
S3_REGION=us-east-1
S3_ACCESS_KEY=changeme
S3_SECRET_KEY=changeme
S3_BUCKET=swarm

# Polling interval
TICK_SECONDS=10

# Facts worker (Python FastAPI service that calls the LLM for extraction)
FACTS_WORKER_URL=http://127.0.0.1:8010
# By default the worker uses the OpenAI API (OPENAI_API_KEY + OPENAI_MODEL below).
# Set FACTS_WORKER_OLLAMA=1 to route extraction through local Ollama instead.
# FACTS_WORKER_OLLAMA=0
# Set to 1 to use Mastra LLM Agent for tool orchestration instead of the direct pipeline.
# Default (unset or 0): direct pipeline calls readContext -> worker /extract -> writeFacts.
# FACTS_USE_MASTRA=0
# Set to 1 to embed claim nodes (Ollama bge-m3) after syncing facts to the semantic graph.
# FACTS_SYNC_EMBED=0

# OpenAI-compatible endpoint (worker + optional Mastra agent). Put real key only in .env (gitignored).
# OPENAI_BASE_URL is always passed to Mastra so it uses chat/completions (not the Responses API).
OPENAI_API_KEY=sk-xxxx
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4o-mini
# Optional: smaller/cheaper model for the oversight (routing) agent; defaults to OPENAI_MODEL.
# OVERSEE_MODEL=gpt-4o-mini

# Postgres (local dev, port 5433 to avoid conflict with other instances)
POSTGRES_USER=swarm
POSTGRES_PASSWORD=changeme
POSTGRES_DB=swarm
DATABASE_URL=postgresql://swarm:changeme@localhost:5433/swarm

# NATS JetStream (event bus)
NATS_URL=nats://localhost:4222
NATS_STREAM=SWARM_JOBS

# Scope id for finality and multi-tenant readiness (v0.1 single-scope default)
SCOPE_ID=default

# Swarm agent identity
AGENT_ID=agent-1
AGENT_ROLE=facts

# Optional: bootstrap jobs on first run
# BOOTSTRAP=1

# Optional: governance config path
# GOVERNANCE_PATH=./governance.yaml

# OpenFGA (policy check). HTTP API on 8080; Playground at http://localhost:3000/playground (port 3000 root / returns 404)
# OPENFGA_URL=http://localhost:8080
# OPENFGA_STORE_ID=
# OPENFGA_MODEL_ID=
# OPENFGA_ALLOW_IF_UNAVAILABLE=1

# MITL approval server (governance agent). Feed uses this to proxy GET /pending and POST /finality-response.
# MITL_PORT=3001
# MITL_URL=http://localhost:3001

# Agent log files (swarm-all.sh). Default /tmp; logs written as swarm-<role>.log.
# LOG_DIR=/tmp

# OpenTelemetry. Agents export traces + metrics to the OTEL collector which
# feeds Prometheus (port 9090). Grafana (port 3004) ships a pre-provisioned dashboard.
OTEL_SERVICE_NAME=swarm-v0.1
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318
# OTEL_SDK_DISABLED=0

# Grafana (docker compose). Anonymous viewer access enabled by default.
# GRAFANA_PASSWORD=swarm

# Phoenix LLM tracing (optional). Configure in facts-worker or set PHOENIX_COLLECTOR_ENDPOINT for OpenInference.
# PHOENIX_COLLECTOR_ENDPOINT=http://localhost:6006

# Planner LLM timeout (ms). Prevents indefinite stall when OpenAI/Ollama is slow.
# Default 60000 (60s). Increase for heavy runs.
# PLANNER_LLM_TIMEOUT_MS=60000

# Ollama (local LLM). Used by TS agents (drift, planner, governance) for rationale/HITL/embeddings.
# The facts-worker only uses Ollama when FACTS_WORKER_OLLAMA=1 (see above).
# Use 127.0.0.1 (not localhost) — Node 18 fetch resolves localhost to IPv6 ::1 first; Ollama binds IPv4 only.
# docker-compose.yml auto-overrides to host.docker.internal for containers.
OLLAMA_BASE_URL=http://127.0.0.1:11434
EXTRACTION_MODEL=qwen3:8b
RATIONALE_MODEL=phi4-mini
HITL_MODEL=mistral-small:22b
EMBEDDING_MODEL=bge-m3

# NER/NLI (optional, requires requirements-full.txt in the facts-worker).
# The slim Docker image skips these. To enable: install requirements-full.txt, set SKIP_*=0, and set models.
# HF_TOKEN=hf_...
# SKIP_GLINER=0
# GLINER_MODEL=fastino/gliner2-base-v1
# SKIP_NLI=0
# NLI_MODEL=cross-encoder/nli-deberta-v3-small

# Finality thresholds (goal gradient HITL vs automatic RESOLVED)
# For the demo scenario, 0.40 ensures HITL triggers after 5 docs (goal_score ~0.45-0.55)
NEAR_FINALITY_THRESHOLD=0.40
AUTO_FINALITY_THRESHOLD=0.92
